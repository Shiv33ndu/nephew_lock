# Nephew-Lock: Smart Device Privacy for Families
*Because my 9-month-old nephew shouldn't be emailing my boss.*

An intelligent screen-locking service designed for tablets and mobile devices. Using a Siamese Network architecture and MobileFaceNet, the application detects a specific childâ€™s face and immediately locks the device to prevent unauthorized access or accidental "toddler-interference." Features a "Supervised Mode" that keeps the device unlocked when a recognized adult is also present in the frame.

This application utilizes MobileFaceNet to generate 128-d embeddings and One-shot face verification, optimized for resource-constrained Android devices. Key features include custom Triplet Loss training with semi-hard negative mining and an evolving "Gold Standard" embedding using Exponential Moving Averages (EMA) to account for facial changes as a child grows.

## Key Features

- **Privacy-First (Edge AI)**: No facial data is sent to the cloud. All inference and embedding generation happen locally on the device.
- **Intelligent Supervision Logic**: Features a "Dual-Face" logic gate that keeps the device unlocked if a recognized adult is also detected in the frame.
- **Adaptive Recognition**: Implements Exponential Moving Average (EMA) for embeddings, allowing the model to evolve as the childâ€™s facial features change over time.
- **Low-Latency Performance**: Built on MobileFaceNet, optimized for high-speed inference on resource-constrained mobile hardware.

---

## Project Structure 

```
nephew_lock/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                # Original 1:1 photos from your phone
â”‚   â”‚   â”œâ”€â”€ nephew/         # 40+ photos
â”‚   â”‚   â”œâ”€â”€ supervision/    # 60+ photos (Nephew + Adult)
â”‚   â”‚   â””â”€â”€ negatives/      # Generic adult faces (LFW dataset)
â”‚   â”œâ”€â”€ processed/          # Automated output from your cleaning scripts
â”‚   â”‚   â”œâ”€â”€ cropped_faces/  # 112x112 tight crops
â”‚   â”‚   â””â”€â”€ embeddings/     # Pre-calculated .npy vectors for "Gold Standard"
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data_prep/          # Scripts for cleaning and augmentation
â”‚   â”‚   â”œâ”€â”€ blur_detector.py
â”‚   â”‚   â”œâ”€â”€ face_cropper.py
â”‚   â”‚   â””â”€â”€ align_faces.py
â”‚   â”œâ”€â”€ models/             # Siamese Network architecture
â”‚   â”‚   â”œâ”€â”€ mobile_facenet.py
â”‚   â”‚   â””â”€â”€ siamese_base.py
â”‚   â”œâ”€â”€ training/           # Training loops and loss functions
â”‚   â”‚   â””â”€â”€ train_triplet.py
â”‚   â””â”€â”€ inference/          # Deployment-ready code
â”‚       â”œâ”€â”€ detector.py     # Real-time face detection logic
â”‚       â””â”€â”€ lock_trigger.py # Logic for locking the screen
â”œâ”€â”€ notebooks/              # For Andrew Ng-style experimentation
â”‚   â”œâ”€â”€ 01_data_exploration.ipynb
â”‚   â””â”€â”€ 02_threshold_tuning.ipynb
â”œâ”€â”€ models_checkpoints/     # Saved .h5 or TFLite files
â”œâ”€â”€ pyproject.toml          # Enterprise dependency locking
â””â”€â”€ config.yaml             # Thresholds (e.g., lock_dist: 0.6)
```

## Tech Stack & Methodology

### The Model: Siamese Network

Instead of a simple classifier, this project uses a **Siamese Network** to learn a distance metric.

- **Backbone:** MobileFaceNet (Pre-trained on MS-Celeb-1M)
- **Loss Function:** Triplet Loss with Semi-Hard Negative Mining
- **Input:** `$112 \times 112$` Aligned Face Crops


### Data Pipeline

- **Blur Filtering:** Automated Laplacian variance check to discard motion-blurred images
- **Landmark Alignment:** MediaPipe-based rotation to ensure eyes are horizontally level
- **Online Triplet Generation:** Dynamic batch creation to ensure the model stays challenged by "Hard Negatives" (Family Members)


### ðŸ“ˆ Roadmap

- [x] Data collection and manual cleaning
- [x] Automated Face Alignment & Cropping pipeline
- [x] Triplet Generator implementation
- [ ] Training on family-specific "Hard Negatives"
- [ ] TFLite conversion for Samsung Android deployment
- [ ] Android Background Service implementation